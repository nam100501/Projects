{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bx4A4MP-JizG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "h4VGM2FFPYyP",
    "outputId": "423ac30d-7f4a-4738-b278-709e7ab660fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargraves</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargraves          619    France  Female   42   \n",
       "1          2    15647311       Hill          608     Spain  Female   41   \n",
       "2          3    15619304       Onio          502    France  Female   42   \n",
       "3          4    15701354       Boni          699    France  Female   39   \n",
       "4          5    15737888   Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure  Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       2        0              1          1               1           101349   \n",
       "1       1    83808              1          0               1           112543   \n",
       "2       8   159661              3          1               0           113932   \n",
       "3       1        0              2          0               0            93827   \n",
       "4       2   125511              1          1               1            79084   \n",
       "\n",
       "   Exited  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "customer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "91E-WpFQP1RV",
    "outputId": "28cd5612-e604-41df-cfbc-712de7a7f677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customer_data['Exited'].value_counts().plot(kind=\"bar\")\n",
    "customer_data.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TxGs0om5QEfN"
   },
   "outputs": [],
   "source": [
    "dataset = customer_data.drop([\"RowNumber\",\"Surname\",\"CustomerId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ky470aqpQSoD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1607\n",
      "           1       0.57      0.19      0.29       393\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.70      0.58      0.59      2000\n",
      "weighted avg       0.78      0.81      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train with imbalance data\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "model = LogisticRegression() \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1607\n",
      "           1       0.66      0.55      0.60       393\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.74      0.75      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OverSampling (Random OverSampling)\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      1607\n",
      "           1       0.60      0.61      0.60       393\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.75      0.75      0.75      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OverSampling (SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      1607\n",
      "           1       0.46      0.75      0.57       393\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.69      0.77      0.71      2000\n",
      "weighted avg       0.84      0.78      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UnderSampling (Random UnderSampling)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      1607\n",
      "           1       0.71      0.51      0.59       393\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.80      0.73      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UnderSampling (Tomek Links)\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_train_resampled, y_train_resampled = tl.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      1607\n",
      "           1       0.60      0.62      0.61       393\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.75      0.76      0.76      2000\n",
      "weighted avg       0.85      0.84      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HydridSampling (SMOTE and Tomek Links)\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGyyxmDJR-3X",
    "outputId": "bb11b1fd-5f29-47fa-a145-b3b7da43ab8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1607\n",
      "           1       0.74      0.49      0.59       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.81      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cost-sensitive Algorithm (RandomForest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "class_weights = {0: 0.8, 1: 0.2}\n",
    "\n",
    "model = RandomForestClassifier(class_weight=class_weights)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgz0PrxcSVIg",
    "outputId": "4266762d-b91a-489c-9209-c2908cb9a622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1607\n",
      "           1       0.38      0.71      0.50       393\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.72      0.65      2000\n",
      "weighted avg       0.81      0.72      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cost-sensitive Algorithm (LogisticRegression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1607\n",
      "           1       0.76      0.47      0.58       393\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.82      0.72      0.75      2000\n",
      "weighted avg       0.86      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ProbabilityTuning Algorithm (IsotonicRegression)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "dataset_dummy = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "X = dataset_dummy.drop([\"Exited\"],axis=1)\n",
    "y = dataset_dummy['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']]= scaler.transform(X_train[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']] = scaler.transform(X_test[['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']])\n",
    "\n",
    "def print_scores(y_true, y_pred):\n",
    "  print(classification_report(y_true, y_pred))\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(model, method='isotonic')\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print_scores( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
